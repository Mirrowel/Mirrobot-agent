name: opencode

on:
  issue_comment:
    types: [created]

jobs:
  opencode:
    if: |
      (
      contains(github.event.comment.body, ' /oc') ||
      startsWith(github.event.comment.body, '/oc') ||
      contains(github.event.comment.body, ' /opencode') ||
      startsWith(github.event.comment.body, '/opencode')
      ) && (
        github.event.comment.author_association == 'OWNER' ||
        github.event.comment.author_association == 'MEMBER' ||
        github.event.comment.author_association == 'COLLABORATOR'
      )
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: read
      pull-requests: read
      id-token: write
    steps:

      - name: Generate GitHub App Token
        id: generate_token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.BOT_APP_ID }}
          private-key: ${{ secrets.BOT_PRIVATE_KEY }}
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Inject Custom Config (For Proxy Support)
        run: |
          mkdir -p ~/.config/opencode
          CONFIG='{
            "$schema": "https://opencode.ai/config.json",
            "provider": {
              "llm-proxy": {
                "npm": "@ai-sdk/openai-compatible",
                "name": "Proxy",
                "options": {
                  "baseURL": "${{ secrets.PROXY_BASE_URL }}",
                  "apiKey": "${{ secrets.PROXY_API_KEY }}",
                  "timeout": 300000, // 5 minute timeout in ms
                  "headers": {
                    "User-Agent": "OpenCode/1.0",
                    "X-Custom-Header": "your-value"
                  }
                },
                "models": {
                  "main_model": {
                    "id": "${{ secrets.OPENCODE_MODEL }}",
                    "name": "Custom Model",
                    "limit": {
                      "context": 262000,
                      "output": 64192
                    }
                  },
                  "fast_model": {
                    "id": "${{ secrets.OPENCODE_FAST_MODEL }}",
                    "name": "Fast Custom Model",
                    "limit": {
                      "context": 262000,
                      "output": 64192
                    }
                  }
                }
              },
              "model": "llm-proxy/main_model",
              "small_model": "llm-proxy/fast_model",
              "username": "mirrobot-agent",
              "autoupdate": true
            }'
          echo "$CONFIG" > ~/.config/opencode/opencode.json

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          # This path is where pip stores its cache on the runner
          path: ~/.cache/pip
          # The key is crucial. It's created from the OS, Python version, and a hash of your requirements file.
          # A new cache is only created when the requirements.txt file changes.
          key: ${{ runner.os }}-pip-3.12-${{ hashFiles('requirements.txt') }}
          # The restore-key provides a fallback to the most recent cache for this Python version.
          restore-keys: |
            ${{ runner.os }}-pip-3.12

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run opencode
        uses: sst/opencode/github@latest
        env:
          OPENCODE_API_KEY: ${{ secrets.PROXY_API_KEY }}
          GITHUB_TOKEN: ${{ steps.generate_token.outputs.token }}
        with:
          share: true
          token: ${{ steps.generate_token.outputs.token }}